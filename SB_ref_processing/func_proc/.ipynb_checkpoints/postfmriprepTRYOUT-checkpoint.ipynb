{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tryout script to do the whole pipeline on the prf data of one sub\n",
    "# after try to generalize for all tasks \n",
    "# put in Nipype format (do mapNodes because then I can iterate throught files, nicer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from nilearn import image, plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from spynoza.filtering.nodes import Savgol_filter#, Savgol_filter_confounds\n",
    "from spynoza.conversion.nodes import Percent_signal_change\n",
    "from nipype import Node, Function\n",
    "import nipype.pipeline as pe\n",
    "import nipype.interfaces.io as nio\n",
    "from bids.grabbids import BIDSLayout\n",
    "\n",
    "#from nipype.interfaces import fsl\n",
    "#from nipype.interfaces import freesurfer\n",
    "#from nipype.interfaces.utility import Function, IdentityInterface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save relevant params used in json file, \n",
    "# afterwards just need to call the field of the list/dict\n",
    "import json\n",
    "analysis_params = {}\n",
    "json_info = open('SBref_analysis_params.json','r').read()\n",
    "analysis_params.update(json.loads(json_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def SGfilt_confound(confounds, tr, polyorder=3, deriv=0, window_length=120):\n",
    "    import pandas as pd\n",
    "    from scipy.signal import savgol_filter\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    confounds_table = pd.read_csv(confounds, sep='\\t', na_values='n/a') #added this line to original spynoza func because it was giving error when str transformed to float\n",
    "    \n",
    "    window = np.int(window_length / tr)\n",
    "\n",
    "    # Window must be odd\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "\n",
    "    confounds_filt = savgol_filter(confounds_table, window_length=window, polyorder=polyorder,\n",
    "                              deriv=deriv, axis=0, mode='nearest')\n",
    "\n",
    "    new_name = os.path.basename(confounds).split('.')[:-1][0] + '_sg.tsv'\n",
    "    out_file = os.path.abspath(new_name)\n",
    "\n",
    "    confounds_table = np.asarray(confounds_table).astype(np.float64) # needed to convert to float to support next operation\n",
    "    pd.DataFrame(confounds_table - confounds_filt).to_csv(out_file, sep='\\t', index=False)\n",
    "\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths and variables\n",
    "sub_list = ['2']\n",
    "ses_list = ['1']\n",
    "task='soma'\n",
    "\n",
    "source_pth = '/home/neuro/projects/data/derivatives/fmriprep/'\n",
    "dest_pth = '/home/neuro/projects/data/derivatives/post_fmriprep/'\n",
    "sub_num = str(sub_list[0]).zfill(2)\n",
    "ses_num = str(ses_list[0]).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets preprocessed niftis from derivative folder\n",
    "layout = BIDSLayout(source_pth)\n",
    "funcdata = layout.get(subject=sub_num,task=task,extensions='space-T1w_preproc.nii.gz',return_type='file') # list of paths to functionals for this sub\n",
    "confdata = layout.get(subject=sub_num,task=task,extensions='.tsv',return_type='file')  # list of paths to confounds for this sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/neuro/projects/data/derivatives/fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-01_bold_space-T1w_preproc.nii.gz',\n",
       " '/home/neuro/projects/data/derivatives/fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-02_bold_space-T1w_preproc.nii.gz',\n",
       " '/home/neuro/projects/data/derivatives/fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-03_bold_space-T1w_preproc.nii.gz',\n",
       " '/home/neuro/projects/data/derivatives/fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-04_bold_space-T1w_preproc.nii.gz']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some HP filtering (Savitzky–Golay) on bold + confounds\n",
    "# define Nodes\n",
    "SG_filter = pe.MapNode(interface=Savgol_filter,\n",
    "                       name='savgol_filt',\n",
    "                       iterfield=['in_file'])\n",
    "SG_filter_confounds = pe.MapNode(Function(function=SGfilt_confound),\n",
    "                       name='sgfilt_confound',\n",
    "                       iterfield=['confounds']) #iterfied needs different name because of temp dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define settings, right ones? \n",
    "SG_filter.inputs.polyorder = SG_filter_confounds.inputs.polyorder = analysis_params['sgfilter_polyorder']\n",
    "SG_filter.inputs.deriv = SG_filter_confounds.inputs.deriv = analysis_params['sgfilter_deriv']\n",
    "SG_filter.inputs.window_length = SG_filter_confounds.inputs.window_length = analysis_params['sgfilter_window_length']\n",
    "\n",
    "if (sub_num=='01' or sub_num=='03') and ses_num=='01': # exception for some initial subjects' sessions\n",
    "    SG_filter.inputs.tr = SG_filter_confounds.inputs.tr = 1.5\n",
    "else:\n",
    "    SG_filter.inputs.tr = SG_filter_confounds.inputs.tr = analysis_params['TR'] \n",
    "\n",
    "SG_filter.inputs.in_file = funcdata\n",
    "SG_filter_confounds.inputs.confounds = confdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:48:56,310 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"savgol_filt\" in \"/tmp/tmp6r4583l1/savgol_filt\".\n",
      "190117-17:48:56,318 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_savgol_filt0\" in \"/tmp/tmp6r4583l1/savgol_filt/mapflow/_savgol_filt0\".\n",
      "190117-17:48:56,324 nipype.workflow INFO:\n",
      "\t [Node] Running \"_savgol_filt0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:49:19,330 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_savgol_filt0\".\n",
      "190117-17:49:19,335 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_savgol_filt1\" in \"/tmp/tmp6r4583l1/savgol_filt/mapflow/_savgol_filt1\".\n",
      "190117-17:49:19,340 nipype.workflow INFO:\n",
      "\t [Node] Running \"_savgol_filt1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:49:42,330 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_savgol_filt1\".\n",
      "190117-17:49:42,332 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_savgol_filt2\" in \"/tmp/tmp6r4583l1/savgol_filt/mapflow/_savgol_filt2\".\n",
      "190117-17:49:42,336 nipype.workflow INFO:\n",
      "\t [Node] Running \"_savgol_filt2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:50:05,529 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_savgol_filt2\".\n",
      "190117-17:50:05,532 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_savgol_filt3\" in \"/tmp/tmp6r4583l1/savgol_filt/mapflow/_savgol_filt3\".\n",
      "190117-17:50:05,536 nipype.workflow INFO:\n",
      "\t [Node] Running \"_savgol_filt3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:50:28,723 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_savgol_filt3\".\n",
      "190117-17:50:28,727 nipype.workflow INFO:\n",
      "\t [Node] Finished \"savgol_filt\".\n"
     ]
    }
   ],
   "source": [
    "# run and print outputs\n",
    "res_SG_filter = SG_filter.run()\n",
    "#res_SG_filter.outputs.out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:52:17,205 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"sgfilt_confound\" in \"/tmp/tmpm0lc934h/sgfilt_confound\".\n",
      "190117-17:52:17,217 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_sgfilt_confound0\" in \"/tmp/tmpm0lc934h/sgfilt_confound/mapflow/_sgfilt_confound0\".\n",
      "190117-17:52:17,223 nipype.workflow INFO:\n",
      "\t [Node] Running \"_sgfilt_confound0\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:52:17,259 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_sgfilt_confound0\".\n",
      "190117-17:52:17,262 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_sgfilt_confound1\" in \"/tmp/tmpm0lc934h/sgfilt_confound/mapflow/_sgfilt_confound1\".\n",
      "190117-17:52:17,267 nipype.workflow INFO:\n",
      "\t [Node] Running \"_sgfilt_confound1\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:52:17,295 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_sgfilt_confound1\".\n",
      "190117-17:52:17,298 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_sgfilt_confound2\" in \"/tmp/tmpm0lc934h/sgfilt_confound/mapflow/_sgfilt_confound2\".\n",
      "190117-17:52:17,308 nipype.workflow INFO:\n",
      "\t [Node] Running \"_sgfilt_confound2\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:52:17,347 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_sgfilt_confound2\".\n",
      "190117-17:52:17,350 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_sgfilt_confound3\" in \"/tmp/tmpm0lc934h/sgfilt_confound/mapflow/_sgfilt_confound3\".\n",
      "190117-17:52:17,353 nipype.workflow INFO:\n",
      "\t [Node] Running \"_sgfilt_confound3\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "190117-17:52:17,380 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_sgfilt_confound3\".\n",
      "190117-17:52:17,384 nipype.workflow INFO:\n",
      "\t [Node] Finished \"sgfilt_confound\".\n"
     ]
    }
   ],
   "source": [
    "res_SG_filter_confounds = SG_filter_confounds.run()\n",
    "#res_SG_filter_confounds.outputs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data to percent signal change\n",
    "#define Nodes\n",
    "psc = pe.MapNode(interface=Percent_signal_change, \n",
    "              name='percent_signal_change',\n",
    "             iterfield = ['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define settings\n",
    "psc.inputs.func = 'median'\n",
    "psc.inputs.in_file = res_SG_filter.outputs.out_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:52:21,182 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"percent_signal_change\" in \"/tmp/tmpekn0twct/percent_signal_change\".\n",
      "190117-17:52:21,189 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_percent_signal_change0\" in \"/tmp/tmpekn0twct/percent_signal_change/mapflow/_percent_signal_change0\".\n",
      "190117-17:52:21,193 nipype.workflow INFO:\n",
      "\t [Node] Running \"_percent_signal_change0\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:37: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:52:39,754 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_percent_signal_change0\".\n",
      "190117-17:52:39,756 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_percent_signal_change1\" in \"/tmp/tmpekn0twct/percent_signal_change/mapflow/_percent_signal_change1\".\n",
      "190117-17:52:39,759 nipype.workflow INFO:\n",
      "\t [Node] Running \"_percent_signal_change1\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:37: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:52:58,369 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_percent_signal_change1\".\n",
      "190117-17:52:58,371 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_percent_signal_change2\" in \"/tmp/tmpekn0twct/percent_signal_change/mapflow/_percent_signal_change2\".\n",
      "190117-17:52:58,374 nipype.workflow INFO:\n",
      "\t [Node] Running \"_percent_signal_change2\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:37: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:53:16,781 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_percent_signal_change2\".\n",
      "190117-17:53:16,784 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_percent_signal_change3\" in \"/tmp/tmpekn0twct/percent_signal_change/mapflow/_percent_signal_change3\".\n",
      "190117-17:53:16,789 nipype.workflow INFO:\n",
      "\t [Node] Running \"_percent_signal_change3\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:37: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:53:36,360 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_percent_signal_change3\".\n",
      "190117-17:53:36,367 nipype.workflow INFO:\n",
      "\t [Node] Finished \"percent_signal_change\".\n"
     ]
    }
   ],
   "source": [
    "# run and print outputs\n",
    "res_psc = psc.run()\n",
    "#res_psc.outputs.out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nistats_confound_pca_glm(nifti_file, confounds_file,output_pth):# which_confounds,output_pth):    # function adapted from utils.py in pearl_7T Git\n",
    "    \n",
    "    import pandas as pd\n",
    "    import nibabel as nb\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from nistats.regression import OLSModel\n",
    "    from scipy.stats import zscore\n",
    "    from nilearn.image import math_img\n",
    "    from nilearn.plotting import plot_stat_map\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    infile = nb.load(nifti_file)\n",
    "    mean_img = math_img('np.mean(infile, axis=-1)', infile=infile)\n",
    "    in_data = infile.get_data().astype(np.float32)\n",
    "    \n",
    "    confounds_table = pd.read_csv(confounds_file, sep='\\t', na_values='n/a')#[which_confounds] #select subgroup of confounds\n",
    "    \n",
    "    # Z-SCORING 1ST, THEN OBTAINING COMPONENTS\n",
    "    # we assume the confounds nor the nifti_file need temporal filtering \n",
    "    z_conf = confounds_table.apply(zscore) #do zscore of each value in the sample (scale data matrix)\n",
    "    \n",
    "    pca = PCA(0.95,whiten=True) #choose the minimum number of principal components such that at least 95% of the variance is retained.\n",
    "    pca_confs = pca.fit_transform(np.nan_to_num(z_conf))\n",
    "    num_comp = pca.n_components_\n",
    "\n",
    "    all_confs = pd.DataFrame(pca_confs, columns=['comp_{n}'.format(n=n) for n in range(num_comp)])\n",
    "    all_confs['intercept'] = np.ones(infile.shape[-1]) #add an intercept column filled with ones\n",
    "    \n",
    "    om = OLSModel(np.array(all_confs)) #create a least squares model based on nuisances\n",
    "    om_rr = om.fit(in_data.reshape((-1,infile.shape[-1])).T) #fit bold data to model\n",
    "    \n",
    "    resid_img = nb.Nifti1Image(om_rr.resid.T.reshape(infile.shape).astype(np.float32), affine=infile.affine, header=infile.header)\n",
    "    cleaned_img = math_img('(resid_img + mean_img[...,np.newaxis]).astype(np.float32)', resid_img=resid_img, mean_img=mean_img)\n",
    "    \n",
    "    output_nifti = output_pth+os.path.basename(nifti_file).replace('.nii.gz', '_nuis.nii.gz')\n",
    "    cleaned_img.to_filename(output_nifti)\n",
    "    \n",
    "    output_pdf = output_pth+os.path.basename(confounds_file).replace('.tsv', '_sd-diff.pdf')\n",
    "    f = plt.figure(figsize=(24,6))\n",
    "    plot_stat_map(math_img('(infile.std(axis=-1)-cleaned_img.std(axis=-1))/infile.std(axis=-1)', infile=infile, cleaned_img=cleaned_img), \n",
    "                bg_img=mean_img, figure=f, cut_coords=(0,0,0), threshold=0.125, vmax=1, cmap='viridis', output_file=output_pdf)\n",
    "    \n",
    "    return output_pdf, output_nifti\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # STANDARD SCALING 1ST, THEN OBTAINING COMPONENTS\n",
    "# # we assume the confounds nor the nifti_file need temporal filtering \n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# stand_conf = StandardScaler().fit_transform(np.nan_to_num(confounds_table))\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(0.95,whiten=True) #choose the minimum number of principal components such that 95% of the variance is retained.\n",
    "# pca_confs = pca.fit_transform(np.nan_to_num(stand_conf))\n",
    "# num_comp = pca.n_components_\n",
    "\n",
    "# print(pca.explained_variance_)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "# all_confs = pd.DataFrame(pca_confs, columns=['comp_{n}'.format(n=n) for n in range(num_comp)])\n",
    "# print(all_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # NO SCALING, JUST OBTAINING COMPONENTS\n",
    "# # we assume the confounds nor the nifti_file need temporal filtering \n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(0.95,whiten=True) #choose the minimum number of principal components such that 95% of the variance is retained.\n",
    "# pca_confs = pca.fit_transform(np.nan_to_num(confounds_table))\n",
    "# num_comp = pca.n_components_\n",
    "\n",
    "# print(pca.explained_variance_)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "# all_confs = pd.DataFrame(pca_confs, columns=['comp_{n}'.format(n=n) for n in range(num_comp)])\n",
    "# print(all_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use confounds as nuisance regressors in a GLM\n",
    "#define Node\n",
    "confGLM = pe.MapNode(Function(input_names=['nifti_file', 'confounds_file', 'output_pth'],#'which_confounds','output_pth'], \n",
    "                              output_names=['output_pdf', 'output_nifti'],\n",
    "                             function=nistats_confound_pca_glm),\n",
    "                             name='nistats_confound_pca_glm', \n",
    "                             iterfield=[\"nifti_file\", \"confounds_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define settings\n",
    "#confGLM.inputs.which_confounds = analysis_params['nuisance_columns']\n",
    "confGLM.inputs.nifti_file = res_psc.outputs.out_file\n",
    "confGLM.inputs.confounds_file = res_SG_filter_confounds.outputs.out\n",
    "confGLM.inputs.output_pth = dest_pth+'sub-'+sub_num+'/ses-'+ses_num+'/func/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:54:07,395 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"nistats_confound_pca_glm\" in \"/tmp/tmpoxfh5nzh/nistats_confound_pca_glm\".\n",
      "190117-17:54:07,402 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_nistats_confound_pca_glm0\" in \"/tmp/tmpoxfh5nzh/nistats_confound_pca_glm/mapflow/_nistats_confound_pca_glm0\".\n",
      "190117-17:54:07,407 nipype.workflow INFO:\n",
      "\t [Node] Running \"_nistats_confound_pca_glm0\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/numpy/core/_methods.py:138: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ret = um.sqrt(ret, out=ret)\n",
      "<string>:1: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:54:29,870 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_nistats_confound_pca_glm0\".\n",
      "190117-17:54:29,873 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_nistats_confound_pca_glm1\" in \"/tmp/tmpoxfh5nzh/nistats_confound_pca_glm/mapflow/_nistats_confound_pca_glm1\".\n",
      "190117-17:54:29,877 nipype.workflow INFO:\n",
      "\t [Node] Running \"_nistats_confound_pca_glm1\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:54:52,122 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_nistats_confound_pca_glm1\".\n",
      "190117-17:54:52,124 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_nistats_confound_pca_glm2\" in \"/tmp/tmpoxfh5nzh/nistats_confound_pca_glm/mapflow/_nistats_confound_pca_glm2\".\n",
      "190117-17:54:52,127 nipype.workflow INFO:\n",
      "\t [Node] Running \"_nistats_confound_pca_glm2\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:55:14,278 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_nistats_confound_pca_glm2\".\n",
      "190117-17:55:14,281 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_nistats_confound_pca_glm3\" in \"/tmp/tmpoxfh5nzh/nistats_confound_pca_glm/mapflow/_nistats_confound_pca_glm3\".\n",
      "190117-17:55:14,285 nipype.workflow INFO:\n",
      "\t [Node] Running \"_nistats_confound_pca_glm3\" (\"nipype.interfaces.utility.wrappers.Function\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190117-17:55:36,315 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_nistats_confound_pca_glm3\".\n",
      "190117-17:55:36,321 nipype.workflow INFO:\n",
      "\t [Node] Finished \"nistats_confound_pca_glm\".\n"
     ]
    }
   ],
   "source": [
    "# run and print outputs\n",
    "res_confGLM = confGLM.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-01_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       " '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-02_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       " '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-03_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       " '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-04_bold_space-T1w_preproc_sg_psc_nuis.nii.gz']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_confGLM.outputs.output_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_lists(input_list):\n",
    "    \"\"\"leave_one_out_lists takes creates a list of lists, with each element\n",
    "    of the input_list left out of the returned lists once, in order.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_list : list\n",
    "        list of items, for instance absolute paths to nii files\n",
    "    Returns\n",
    "    -------\n",
    "    output_data : list\n",
    "        list of lists\n",
    "    \"\"\"\n",
    "\n",
    "    out_lists = []\n",
    "    for x in input_list:\n",
    "        out_lists.append([y for y in input_list if y != x])\n",
    "\n",
    "    return out_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-02_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-03_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-04_bold_space-T1w_preproc_sg_psc_nuis.nii.gz'],\n",
       " ['/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-01_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-03_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-04_bold_space-T1w_preproc_sg_psc_nuis.nii.gz'],\n",
       " ['/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-01_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-02_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-04_bold_space-T1w_preproc_sg_psc_nuis.nii.gz'],\n",
       " ['/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-01_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-02_bold_space-T1w_preproc_sg_psc_nuis.nii.gz',\n",
       "  '/home/neuro/projects/data/derivatives/post_fmriprep/sub-02/ses-01/func/sub-02_ses-01_task-soma_run-03_bold_space-T1w_preproc_sg_psc_nuis.nii.gz']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leave_one_out_lists(res_confGLM.outputs.output_nifti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY TO LOOK AT SOMA DATA ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "somas = res_confGLM.outputs.output_nifti # list of residual niftis\n",
    "mean_filename = (res_confGLM.outputs.output_nifti[0]).replace('run-01', 'run-mean')\n",
    "\n",
    "mean_soma=image.math_img('(i1+i2+i3+i4)/4', i1=somas[0], i2=somas[1], i3=somas[2],i4=somas[3])\n",
    "mean_soma.to_filename(mean_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_stims = len(analysis_params['soma_stimulus']) #number of stim videos\n",
    "stimulus_setup = np.array([s.split('.avi')[0] for s in analysis_params['soma_stimulus']]) # name for all regressors\n",
    "different_regressors = np.unique(stimulus_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  12.  ,   14.75,   17.5 ,   20.25,   23.  ,   25.75,   28.5 ,\n",
       "         31.25,   34.  ,   36.75,   39.5 ,   42.25,   45.  ,   47.75,\n",
       "         50.5 ,   53.25,   56.  ,   58.75,   61.5 ,   64.25,   67.  ,\n",
       "         69.75,   72.5 ,   75.25,   78.  ,   80.75,   83.5 ,   86.25,\n",
       "         89.  ,   91.75,   94.5 ,   97.25,  100.  ,  102.75,  105.5 ,\n",
       "        108.25,  111.  ,  113.75,  116.5 ,  119.25,  122.  ,  124.75,\n",
       "        127.5 ,  130.25,  133.  ,  135.75,  138.5 ,  141.25,  144.  ,\n",
       "        146.75,  149.5 ,  152.25,  155.  ,  157.75,  160.5 ,  163.25,\n",
       "        166.  ,  168.75,  171.5 ,  174.25])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_times = np.arange(0, 2.75*nr_stims, 2.75) + 12\n",
    "onset_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bhand_fing1': array([  50.5,  144. ]),\n",
       " 'bhand_fing2': array([  53.25,  141.25]),\n",
       " 'bhand_fing3': array([  56. ,  138.5]),\n",
       " 'bhand_fing4': array([  58.75,  135.75]),\n",
       " 'bhand_fing5': array([  61.5,  133. ]),\n",
       " 'bleg': array([  64.25,  146.75]),\n",
       " 'eyebrows': array([  12.  ,   39.5 ,   75.25,   94.5 ,  122.  ,  157.75]),\n",
       " 'eyes': array([  14.75,   42.25,   72.5 ,   97.25,  124.75,  155.  ]),\n",
       " 'lhand_fing1': array([  23. ,  116.5]),\n",
       " 'lhand_fing2': array([  25.75,  113.75]),\n",
       " 'lhand_fing3': array([  28.5,  111. ]),\n",
       " 'lhand_fing4': array([  31.25,  108.25]),\n",
       " 'lhand_fing5': array([  34. ,  105.5]),\n",
       " 'lleg': array([  36.75,  119.25]),\n",
       " 'mouth': array([  17.5 ,   45.  ,   69.75,  100.  ,  127.5 ,  152.25]),\n",
       " 'rhand_fing1': array([  78. ,  171.5]),\n",
       " 'rhand_fing2': array([  80.75,  168.75]),\n",
       " 'rhand_fing3': array([  83.5,  166. ]),\n",
       " 'rhand_fing4': array([  86.25,  163.25]),\n",
       " 'rhand_fing5': array([  89. ,  160.5]),\n",
       " 'rleg': array([  91.75,  174.25]),\n",
       " 'tongue': array([  20.25,   47.75,   67.  ,  102.75,  130.25,  149.5 ])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{er: onset_times[stimulus_setup==er] for er in different_regressors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stim_onset_list = []\n",
    "for i, s in enumerate(stimulus_setup):\n",
    "    if s[0] == 'b':\n",
    "        stim_onset_list.append([onset_times[i], 2.25, 'l'+s[1:]])\n",
    "        stim_onset_list.append([onset_times[i], 2.25, 'r'+s[1:]])        \n",
    "    stim_onset_list.append([onset_times[i], 2.25, s])\n",
    "events = pd.DataFrame(stim_onset_list, columns=['onset','duration','trial_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eyebrows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>tongue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eyebrows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>42.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>tongue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>56.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>56.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>58.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>58.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>61.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>61.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>61.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>127.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>130.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>tongue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>133.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>133.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>133.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>135.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>135.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>135.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>138.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>138.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>138.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>141.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>141.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>141.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>144.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>144.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>144.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>146.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>lleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>146.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>146.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>bleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>149.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>tongue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>152.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>155.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>157.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>eyebrows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>160.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>163.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>166.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>168.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>171.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rhand_fing1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>174.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>rleg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     onset  duration   trial_type\n",
       "0    12.00      2.25     eyebrows\n",
       "1    14.75      2.25         eyes\n",
       "2    17.50      2.25        mouth\n",
       "3    20.25      2.25       tongue\n",
       "4    23.00      2.25  lhand_fing1\n",
       "5    25.75      2.25  lhand_fing2\n",
       "6    28.50      2.25  lhand_fing3\n",
       "7    31.25      2.25  lhand_fing4\n",
       "8    34.00      2.25  lhand_fing5\n",
       "9    36.75      2.25         lleg\n",
       "10   39.50      2.25     eyebrows\n",
       "11   42.25      2.25         eyes\n",
       "12   45.00      2.25        mouth\n",
       "13   47.75      2.25       tongue\n",
       "14   50.50      2.25  lhand_fing1\n",
       "15   50.50      2.25  rhand_fing1\n",
       "16   50.50      2.25  bhand_fing1\n",
       "17   53.25      2.25  lhand_fing2\n",
       "18   53.25      2.25  rhand_fing2\n",
       "19   53.25      2.25  bhand_fing2\n",
       "20   56.00      2.25  lhand_fing3\n",
       "21   56.00      2.25  rhand_fing3\n",
       "22   56.00      2.25  bhand_fing3\n",
       "23   58.75      2.25  lhand_fing4\n",
       "24   58.75      2.25  rhand_fing4\n",
       "25   58.75      2.25  bhand_fing4\n",
       "26   61.50      2.25  lhand_fing5\n",
       "27   61.50      2.25  rhand_fing5\n",
       "28   61.50      2.25  bhand_fing5\n",
       "29   64.25      2.25         lleg\n",
       "..     ...       ...          ...\n",
       "54  127.50      2.25        mouth\n",
       "55  130.25      2.25       tongue\n",
       "56  133.00      2.25  lhand_fing5\n",
       "57  133.00      2.25  rhand_fing5\n",
       "58  133.00      2.25  bhand_fing5\n",
       "59  135.75      2.25  lhand_fing4\n",
       "60  135.75      2.25  rhand_fing4\n",
       "61  135.75      2.25  bhand_fing4\n",
       "62  138.50      2.25  lhand_fing3\n",
       "63  138.50      2.25  rhand_fing3\n",
       "64  138.50      2.25  bhand_fing3\n",
       "65  141.25      2.25  lhand_fing2\n",
       "66  141.25      2.25  rhand_fing2\n",
       "67  141.25      2.25  bhand_fing2\n",
       "68  144.00      2.25  lhand_fing1\n",
       "69  144.00      2.25  rhand_fing1\n",
       "70  144.00      2.25  bhand_fing1\n",
       "71  146.75      2.25         lleg\n",
       "72  146.75      2.25         rleg\n",
       "73  146.75      2.25         bleg\n",
       "74  149.50      2.25       tongue\n",
       "75  152.25      2.25        mouth\n",
       "76  155.00      2.25         eyes\n",
       "77  157.75      2.25     eyebrows\n",
       "78  160.50      2.25  rhand_fing5\n",
       "79  163.25      2.25  rhand_fing4\n",
       "80  166.00      2.25  rhand_fing3\n",
       "81  168.75      2.25  rhand_fing2\n",
       "82  171.50      2.25  rhand_fing1\n",
       "83  174.25      2.25         rleg\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.60000000000002"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "141*1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
