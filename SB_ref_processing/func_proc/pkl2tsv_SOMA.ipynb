{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to create a nice events tsv for SB ref somatotopy runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths and variables\n",
    "sub_list = ['13','12','1','3','4','5','6','7','8','9']\n",
    "ses_list = ['1']\n",
    "task='soma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in np.arange(len(sub_list)):\n",
    "    sub_num = str(sub_list[k]).zfill(2)\n",
    "    ses_num = str(ses_list[0]).zfill(2)\n",
    "    \n",
    "    data_dir = '/home/neuro/projects/data/sub-'+sub_num+'/ses-'+ses_num+'/func/'\n",
    "    files_pkl = [p for p in os.listdir(data_dir) if task in p and p.endswith('pkl')]; files_pkl.sort() # list of pickles files, for task, sorted\n",
    "    \n",
    "    for j in np.arange(len(files_pkl)):\n",
    "        data_pkl = pd.read_pickle(data_dir+files_pkl[j]) #read data for that run\n",
    "        nr_stims = len(data_pkl['parameterArray']) #number of stim videos\n",
    "        stim_type = np.array([data_pkl['parameterArray'][s]['movie'].split('.avi')[0] for s in np.arange(nr_stims)]) # all trial types\n",
    "    \n",
    "        stim_onset_list = [] # create empty list\n",
    "\n",
    "        for r in np.arange(nr_stims): #for all stim \n",
    "            onset = [i for i in data_pkl['eventArray'][r] if \"phase 2\" in i][-1].split()[-1] #onset time for stim in trial (phase2)\n",
    "            dur = str(float([i for i in data_pkl['eventArray'][r] if \"phase 3\" in i][-1].split()[-1]) - float(onset)) # duration of stim in trial (phase 3-2)\n",
    "            stim_onset_list.append([onset, dur, stim_type[r]]) #append trial\n",
    "     \n",
    "        events = pd.DataFrame(stim_onset_list, columns=['onset','duration','trial_type']) #save as panda data frame\n",
    "        run_num = files_pkl[j].split('_')[-2].split('-')[-1]\n",
    "        output_tsv = data_dir+'sub-'+sub_num+'_ses-'+ses_num+'_task-'+task+'_run-'+run_num+'_events.tsv'\n",
    "        events.to_csv(output_tsv, sep = '\\t')\n",
    "\n",
    "      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/home/neuro/projects/data/sub-'+sub_num+'/ses-'+ses_num+'/func/'\n",
    "# files_pkl = [p for p in os.listdir(data_dir) if task in p and p.endswith('pkl')]; files_pkl.sort() # list of pickles files, for task, sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in np.arange(len(files_pkl)):\n",
    "#     data_pkl = pd.read_pickle(data_dir+files_pkl[j]) #read data for that run\n",
    "#     nr_stims = len(data_pkl['parameterArray']) #number of stim videos\n",
    "#     stim_type = np.array([data_pkl['parameterArray'][s]['movie'].split('.avi')[0] for s in np.arange(nr_stims)]) # all trial types\n",
    "    \n",
    "#     stim_onset_list = [] # create empty list\n",
    "\n",
    "#     for r in np.arange(nr_stims): #for all stim \n",
    "#         onset = [i for i in data_pkl['eventArray'][r] if \"phase 2\" in i][-1].split()[-1] #onset time for stim in trial (phase2)\n",
    "#         dur = str(float([i for i in data_pkl['eventArray'][r] if \"phase 3\" in i][-1].split()[-1]) - float(onset)) # duration of stim in trial (phase 3-2)\n",
    "#         stim_onset_list.append([onset, dur, stim_type[r]]) #append trial\n",
    "     \n",
    "#     events = pd.DataFrame(stim_onset_list, columns=['onset','duration','trial_type']) #save as panda data frame\n",
    "#     run_num = files_pkl[j].split('_')[-2].split('-')[-1]\n",
    "#     output_tsv = data_dir+'sub-'+sub_num+'_ses-'+ses_num+'_task-'+task+'_run-'+run_num+'_events.tsv'\n",
    "#     events.to_csv(output_tsv, sep = '\\t')\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(sub_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
